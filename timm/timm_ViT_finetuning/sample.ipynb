{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium",
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1oF6ex6Pxwy1gt1fNnJ7VLLOefbmZ6VU_",
      "authorship_tag": "ABX9TyMaHTejmGJ0DQn7pTWt7+uT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taiga10969/Learn-the-basics/blob/main/timm/timm_ViT_finetuning/sample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1．必要ライブラリのインポート"
      ],
      "metadata": {
        "id": "z_o5EhQ3ilBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Jd_YTmUm7TYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TUkmidHJzCI1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2．データを用意\n",
        "事前学習モデルを用いる為1辺の画像の長さを224pxに変更して用意する．"
      ],
      "metadata": {
        "id": "nwrz5cRu1Qqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = T.Compose([T.ToTensor(),\n",
        "                        T.Resize(224),\n",
        "                        T.CenterCrop(224),\n",
        "                        T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                        ])\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transforms)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "O_nVFqJTzPND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### データの確認"
      ],
      "metadata": {
        "id": "D3RIpKPLjYEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "for i in range(10):\n",
        "    image, label = train_dataset[i]\n",
        "    #print(image)\n",
        "    image = image / 2 + 0.5  # unnormalize\n",
        "    image = image.numpy()\n",
        "    image = np.transpose(image, (1, 2, 0))\n",
        "    print(image.shape)\n",
        "    ax = plt.subplot(1, 10, i+1)\n",
        "    plt.imshow(image)\n",
        "    ax.axis('off')\n",
        "    ax.set_title('label : {}'.format(classes[int(label)]), fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vRwuiwjN0KF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3．GPUの使用確認"
      ],
      "metadata": {
        "id": "TRawDz37jfnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"device : \", device)"
      ],
      "metadata": {
        "id": "i92xT2akhn5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPUメモリの確認"
      ],
      "metadata": {
        "id": "J3ogmkVmmodv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "_B1T6dYVmmJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4．学習済みモデルの用意"
      ],
      "metadata": {
        "id": "pu7Cr4O7jxjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習･検証を行う関数の用意"
      ],
      "metadata": {
        "id": "6xy95FoRkoo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "\n",
        "    # ネットワークモデルを学習モードに設定\n",
        "    model.train()\n",
        "\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    for data, label in train_loader:\n",
        "        count += len(label)\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        sum_loss += loss.item()\n",
        "\n",
        "    return sum_loss/count"
      ],
      "metadata": {
        "id": "E5g9nZBOhjo5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val(model, val_loader, criterion, device):\n",
        "\n",
        "    # ネットワークモデルを評価モードに設定\n",
        "    model.eval()\n",
        "\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, label in val_loader:\n",
        "            count += len(label)\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, label)\n",
        "            sum_loss += loss.item()\n",
        "            pred = torch.argmax(outputs, dim=1)\n",
        "            correct += torch.sum(pred == label)\n",
        "\n",
        "    accuracy_rate = (correct / count).cpu().detach()\n",
        "\n",
        "    return sum_loss/count, accuracy_rate"
      ],
      "metadata": {
        "id": "4nqjRMAkh1o_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Image Modelsライブラリのインストール"
      ],
      "metadata": {
        "id": "VvrL9J_qkFA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "kTuHy0YOhPq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "from pprint import pprint\n",
        "#model_names = timm.list_models(pretrained=True)\n",
        "#pprint(model_names)"
      ],
      "metadata": {
        "id": "8pPKPM0agqn9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### モデルを生成"
      ],
      "metadata": {
        "id": "qp72DSxPkvOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=10)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "print(\"model : \", model)\n",
        "print(\"criterion : \", criterion)\n",
        "print(\"optimizer : \", optimizer)"
      ],
      "metadata": {
        "id": "TmFQRAsqh3vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5．学習"
      ],
      "metadata": {
        "id": "A_8rFSoTk4Va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch = 25\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "accuracy_rate_list = []\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(1, num_epoch+1, 1):\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, accuracy_rate = val(model, test_loader, criterion, device)\n",
        "\n",
        "    train_loss_list.append(train_loss)\n",
        "    val_loss_list.append(val_loss)\n",
        "    accuracy_rate_list.append(accuracy_rate)\n",
        "\n",
        "    process_time = time.time() - start\n",
        "\n",
        "    print(\"epoch : {}, train_loss : {}, test_loss : {}, accuracy_rate : {}, time : {}\".format(epoch, train_loss, val_loss, accuracy_rate, process_time))\n",
        "print(\"training_time : {}\".format(time.time() - start))"
      ],
      "metadata": {
        "id": "rvw2LBN3iOvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6．学習の確認"
      ],
      "metadata": {
        "id": "zAfEaj8Q2Bw8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### クラス別認識率の算出"
      ],
      "metadata": {
        "id": "1h-DlP7_9p2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "class_count_list = [0,0,0,0,0,0,0,0,0,0]\n",
        "class_accuracy_rate_list = [0,0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "for i in range(len(test_dataset)):\n",
        "    data, label = test_dataset[i]\n",
        "    data  = data.view(-1, 3, 224, 224).to(device)\n",
        "    class_count_list[label] = class_count_list[label] + 1\n",
        "    # 推論\n",
        "    prediction_label = torch.argmax(model(data))\n",
        "    if label == prediction_label:\n",
        "        class_accuracy_rate_list[label] = class_accuracy_rate_list[label] + 1\n",
        "\n",
        "for i in range(10):\n",
        "    class_accuracy = class_accuracy_rate_list[i] / class_count_list[i]\n",
        "    sum_accuracy = sum(class_accuracy_rate_list) / sum(class_count_list)\n",
        "    print(\"class{} : {:.5f}  ( {} / {})\".format(i, class_accuracy, class_accuracy_rate_list[i], class_count_list[i]))\n",
        "print(\"sum_accuracy : {} ( {} / {})\".format(sum_accuracy, sum(class_accuracy_rate_list), sum(class_count_list)))"
      ],
      "metadata": {
        "id": "KM3nTxkJsmJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習曲線の可視化"
      ],
      "metadata": {
        "id": "_-ji6kMI9yFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, len(train_loss_list)+1, 1), train_loss_list, c='b', label='train loss')\n",
        "plt.plot(range(1, len(val_loss_list)+1, 1), val_loss_list, c='r', label='val loss')\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.savefig('Vit_CIFAR-10_finetuning_loss.svg')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0La5EIcJlIQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 学習済みモデルのパラメータを保存"
      ],
      "metadata": {
        "id": "DMmK8D5m9joZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.to('cpu').state_dict(),'model_vit_small_patch16_224_finetuning.pth')"
      ],
      "metadata": {
        "id": "01SFjFxXnI4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp model_vit_small_patch16_224_finetuning.pth /content/drive/MyDrive/OLD/Research/ViT_Research"
      ],
      "metadata": {
        "id": "6sSdboF77jBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}